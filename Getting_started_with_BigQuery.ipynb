{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uttam0017/deoma/blob/main/Getting_started_with_BigQuery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Introduction\n",
        "\n",
        "In this analysis, we will be exploring the COVID-19 data from five main states in Australia â€“ NSW, Vic, QLD, SA, WA. The data covers the numbers of new cases and new deaths on a daily and weekly basis. We will be working with the weekly data, which includes both the daily numbers before September 9, 2022, and the weekly data after that. We will need to aggregate the daily data into weekly data to perform our analysis. The data set for new cases has two columns, NEW and NET, which look similar. We will use the NEW column as it represents the number officially reported by authorities. We will also calculate our own number for total cases using the NEW column. The data set consists of five daily case files and five daily death files for each state."
      ],
      "metadata": {
        "id": "2BQDmkauW2rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tReport and discuss distributions of new cases and deaths weekly numbers in five states. "
      ],
      "metadata": {
        "id": "kGG5KSCqWxgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data for new cases\n",
        "daily_cases_qld = pd.read_csv('daily_cases_qld.tsv', sep='\\t')\n",
        "daily_cases_sa = pd.read_csv('daily_cases_sa.tsv', sep='\\t')\n",
        "daily_cases_nsw = pd.read_csv('daily_cases_nsw.tsv', sep='\\t')\n",
        "daily_cases_wa = pd.read_csv('daily_cases_wa.tsv', sep='\\t')\n",
        "daily_cases_vic = pd.read_csv('daily_cases_vic.tsv', sep='\\t')\n",
        "\n",
        "# Concatenate the data into one DataFrame\n",
        "daily_cases = pd.concat([daily_cases_qld, daily_cases_sa, daily_cases_nsw, daily_cases_wa, daily_cases_vic])\n",
        "\n",
        "# Aggregate the daily data into weekly data\n",
        "weekly_cases = daily_cases.groupby(['STATE', pd.Grouper(key='DATE', freq='W-MON')]).sum().reset_index()\n",
        "\n",
        "# Load the data for new deaths\n",
        "daily_death_qld = pd.read_csv('daily_death_qld.tsv', sep='\\t')\n",
        "daily_death_sa = pd.read_csv('daily_death_sa.tsv', sep='\\t')\n",
        "daily_death_nsw = pd.read_csv('daily_death_nsw.tsv', sep='\\t')\n",
        "daily_death_wa = pd.read_csv('daily_death_wa.tsv', sep='\\t')\n",
        "daily_death_vic = pd.read_csv('daily_death_vic.tsv', sep='\\t')\n",
        "\n",
        "# code for cleaning \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load data from TSV file\n",
        "data = pd.read_csv('daily_cases_nsw.tsv', delimiter='\\t')\n",
        "\n",
        "# Rename columns for consistency\n",
        "data = data.rename(columns={'notification_date': 'date', 'local': 'new_cases'})\n",
        "\n",
        "# Convert date column to datetime format\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "# Filter out rows with missing values in new_cases column\n",
        "data = data[data['new_cases'].notna()]\n",
        "\n",
        "# Calculate total cases by summing new cases over the previous 7 days\n",
        "data['total_cases'] = data['new_cases'].rolling(7).sum()\n",
        "\n",
        "# Merge with population data to normalize by population\n",
        "pop_data = pd.read_csv('population.csv')\n",
        "pop_data = pop_data.rename(columns={'STATE': 'state', 'POPULATION': 'population'})\n",
        "merged_data = pd.merge(data, pop_data, on='state')\n",
        "merged_data['cases_per_100k'] = (merged_data['total_cases'] / merged_data['population']) * 100000\n",
        "\n",
        "# Remove unnecessary columns\n",
        "clean_data = merged_data[['date', 'state', 'cases_per_100k']]\n",
        "\n",
        "# Print the first few rows of the cleaned data\n",
        "print(clean_data.head())\n",
        "\n",
        "\n",
        "# Concatenate the data into one DataFrame\n",
        "daily_death = pd.concat([daily_death_qld, daily_death_sa, daily_death_nsw, daily_death_wa, daily_death_vic])\n",
        "\n",
        "# Aggregate the daily data into weekly data\n",
        "weekly_death = daily_death.groupby(['STATE', pd.Grouper(key='DATE', freq='W-MON')]).sum().reset_index()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "xcCX2_b2PZZ1",
        "outputId": "72ffe0db-d7b6-4449-f503-ff08982f5cc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-96ffcc671b26>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the data for new cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdaily_cases_qld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'daily_cases_qld.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdaily_cases_sa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'daily_cases_sa.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdaily_cases_nsw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'daily_cases_nsw.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'daily_cases_qld.tsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histograms of new cases and deaths weekly numbers in the five states\n",
        "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(20,8))\n",
        "for i, state in enumerate(['QLD', 'SA', 'NSW', 'WA', 'VIC']):\n",
        "    axs[0, i].hist(weekly_cases[weekly_cases['STATE']==state]['NEW'], bins=20)\n",
        "    axs[0, i].set_title(f'New cases in {state}')\n",
        "    axs[1, i].hist(weekly_death[weekly_death['STATE']==state]['NEW'], bins=20)\n",
        "    axs[1, i].set_title(f'New deaths in {state}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create boxplots for new cases\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Distribution of New Cases Weekly Numbers in Five States')\n",
        "plt.ylabel('New Cases')\n",
        "sns.boxplot(data=[cases_qld_weekly['NEW'], cases_sa_weekly['NEW'], cases_nsw_weekly['NEW'], cases_wa_weekly['NEW'], cases_vic_weekly['NEW']])\n",
        "plt.xticks([0, 1, 2, 3, 4], ['QLD', 'SA', 'NSW', 'WA', 'VIC'])\n",
        "plt.show()\n",
        "\n",
        "# Create boxplots for new deaths\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Distribution of New Deaths Weekly Numbers in\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "EgYg0VYKPeVv",
        "outputId": "eb9db505-fe59-4093-b97d-6f58cbdd3548"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-8d8f963523fc>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    plt.title('Distribution of New Deaths Weekly Numbers in\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tCreate a graph similar to the example below to plot the history of COVID-19 in different states. Pay attention that the graph for each state starts on different calendar day as it starts on a day after 100 reported cases. Your graph should start on the week after 1000 cases were reported and then show cumulative weekly numbers as we do a weekly-based analysis. Provide brief comments on the progress of COVID-19.\n"
      ],
      "metadata": {
        "id": "oPK8K-9RWnr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# calculate the weekly cumulative cases for each state\n",
        "def calculate_cumulative_weekly_cases(df):\n",
        "    df = df.loc[df['NEW'] >= 1000]\n",
        "    df['WEEK'] = pd.to_datetime(df['DATE']).dt.to_period('W')\n",
        "    df = df.groupby('WEEK').agg({'NEW': 'sum'}).cumsum()\n",
        "    df.index = df.index.to_timestamp()\n",
        "    return df\n",
        "\n",
        "cumulative_cases_qld = calculate_cumulative_weekly_cases(df_cases_qld)\n",
        "cumulative_cases_sa = calculate_cumulative_weekly_cases(df_cases_sa)\n",
        "cumulative_cases_nsw = calculate_cumulative_weekly_cases(df_cases_nsw)\n",
        "cumulative_cases_wa = calculate_cumulative_weekly_cases(df_cases_wa)\n",
        "cumulative_cases_vic = calculate_cumulative_weekly_cases(df_cases_vic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "tNh807vxSWfQ",
        "outputId": "c4e6fa30-3a10-4b82-8114-aa8e5ac546fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-59f544956aba>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcumulative_cases_qld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cumulative_weekly_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cases_qld\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcumulative_cases_sa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cumulative_weekly_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cases_sa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcumulative_cases_nsw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cumulative_weekly_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cases_nsw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_cases_qld' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the cumulative weekly cases for each state\n",
        "plt.plot(cumulative_cases_qld, label='Queensland')\n",
        "plt.plot(cumulative_cases_sa, label='South Australia')\n",
        "plt.plot(cumulative_cases_nsw, label='New South Wales')\n",
        "plt.plot(cumulative_cases_wa, label='Western Australia')\n",
        "plt.plot(cumulative_cases_vic, label='Victoria')\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Cumulative Weekly Cases')\n",
        "plt.title('COVID-19 Cases by State')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TmjSE8tVSfSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.\tNormalise numbers of new cases by population (see table in the appendix) and plot a calendar-based historical graph of weekly cases. Provide brief comments on similarities and differences"
      ],
      "metadata": {
        "id": "DGB17he5VWFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "population = pd.read_csv(\"population.csv\", index_col=0)\n",
        "\n",
        "\n",
        "# Convert date column to datetime type\n",
        "daily_cases['date'] = pd.to_datetime(daily_cases['date'], format='%Y-%m-%d')\n",
        "\n",
        "# Calculate new cases per week\n",
        "df_cases_weekly = daily_cases.groupby(pd.Grouper(key='date', freq='W-MON')).sum()\n",
        "\n",
        "# Normalize new cases by population\n",
        "for state in population.index:\n",
        "    df_cases_weekly[state] = df_cases_weekly[state] / population.loc[state, 'population'] * 100000\n",
        "\n",
        "# Plot graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.lineplot(data=df_cases_weekly)\n",
        "plt.title(\"Weekly new COVID-19 cases per 100,000 population by state\")\n",
        "plt.ylabel(\"New cases per 100,000 population\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "r9pog95zT9P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\tStudy a relationship between number of new cases and deaths in five states. "
      ],
      "metadata": {
        "id": "NJBjwkCvVIgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge case and death data by week and state\n",
        "weekly_data = pd.merge(weekly_cases, weekly_deaths, on=['week', 'state'])\n",
        "\n",
        "# Calculate new cases and deaths per capita\n",
        "for state in weekly_data['state'].unique():\n",
        "    pop = populations.loc[state, 'population']\n",
        "    weekly_data.loc[weekly_data['state'] == state, 'new_cases_per_capita'] = weekly_data.loc[weekly_data['state'] == state, 'new_cases'] / pop * 100000\n",
        "    weekly_data.loc[weekly_data['state'] == state, 'new_deaths_per_capita'] = weekly_data.loc[weekly_data['state'] == state, 'new_deaths'] / pop * 100000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "LEbVc90BU_q6",
        "outputId": "e37a5d27-a6fa-4a5f-9288-e10851829a15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c482fe93defb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merge case and death data by week and state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweekly_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweekly_deaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate new cases and deaths per capita\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweekly_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'weekly_cases' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create scatter plots\n",
        "for state in weekly_data['state'].unique():\n",
        "    plt.scatter(weekly_data.loc[weekly_data['state'] == state, 'new_cases_per_capita'], \n",
        "                weekly_data.loc[weekly_data['state'] == state, 'new_deaths_per_capita'],\n",
        "                label=state)\n",
        "plt.xlabel('New Cases per Capita')\n",
        "plt.ylabel('New Deaths per Capita')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hVo1KeDyVCIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Getting started with BigQuery",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}